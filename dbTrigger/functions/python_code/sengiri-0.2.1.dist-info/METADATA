Metadata-Version: 2.1
Name: sengiri
Version: 0.2.1
Summary: Yet another sentence-level tokenizer for the Japanese text
Home-page: https://github.com/ikegami-yukino/sengiri
Author: Yukino Ikegami
Author-email: yknikgm@gmail.com
License: MIT License
Keywords: japanese,tokenizer,sentence,sentence-tokenizer
Platform: POSIX
Platform: Windows
Platform: Unix
Platform: MacOS
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Information Technology
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: Japanese
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft
Classifier: Operating System :: POSIX
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Topic :: Text Processing
Requires-Dist: emoji

sengiri
==========
|travis| |coveralls| |pyversion| |version| |license|

Yet another sentence-level tokenizer for the Japanese text

DEPENDENCY
==============

MeCab

INSTALLATION
==============

::

 $ pip install sengiri


USAGE
============

.. code:: python

  import sengiri

  print(sengiri.tokenize('ã†ãƒ¼ã‚“ðŸ¤”ðŸ¤”ðŸ¤”ã©ã†ã—ã‚ˆã†'))
  #=>['ã†ãƒ¼ã‚“ðŸ¤”ðŸ¤”ðŸ¤”', 'ã©ã†ã—ã‚ˆã†']
  print(sengiri.tokenize('ãƒ¢ãƒ¼å¨˜ã€‚ã®ã‚³ãƒ³ã‚µãƒ¼ãƒˆã«è¡Œã£ãŸã€‚'))
  #=>['ãƒ¢ãƒ¼å¨˜ã€‚ã®ã‚³ãƒ³ã‚µãƒ¼ãƒˆã«è¡Œã£ãŸã€‚']
  print(sengiri.tokenize('ã‚ã‚ŠãŒã¨ã†ï¼¾ï¼¾ åŠ©ã‹ã‚Šã¾ã™ã€‚'))
  #=>['ã‚ã‚ŠãŒã¨ã†ï¼¾ï¼¾', 'åŠ©ã‹ã‚Šã¾ã™ã€‚']
  print(sengiri.tokenize('é¡”æ–‡å­—ãƒ†ã‚¹ãƒˆ(*Â´Ï‰ï½€*)ã†ã¾ãã„ãã‹ãªï¼Ÿ'))
  #=>['é¡”æ–‡å­—ãƒ†ã‚¹ãƒˆ(*Â´Ï‰ï½€*)ã†ã¾ãã„ãã‹ãªï¼Ÿ']
  # I recommend using the NEologd dictionary.
  print(sengiri.tokenize('é¡”æ–‡å­—ãƒ†ã‚¹ãƒˆ(*Â´Ï‰ï½€*)ã†ã¾ãã„ãã‹ãªï¼Ÿ', mecab_args='-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd'))
  #=>['é¡”æ–‡å­—ãƒ†ã‚¹ãƒˆ(*Â´Ï‰ï½€*)', 'ã†ã¾ãã„ãã‹ãªï¼Ÿ']
  print(sengiri.tokenize('å­ä¾›ãŒå¤§å¤‰ãªã“ã¨ã«ãªã£ãŸã€‚'
                         'ï¼ˆå¾Œã§èžã„ãŸã®ã ãŒã€è„…ã•ã‚ŒãŸã‚‰ã—ã„ï¼‰'
                         'ï¼ˆè„…è¿«ã¯ã‚„ã‚ã¦ã»ã—ã„ã¨è¨€ã£ã¦ã„ã‚‹ã®ã«ï¼‰'))
  #=>['å­ä¾›ãŒå¤§å¤‰ãªã“ã¨ã«ãªã£ãŸã€‚', 'ï¼ˆå¾Œã§èžã„ãŸã®ã ãŒã€è„…ã•ã‚ŒãŸã‚‰ã—ã„ï¼‰', 'ï¼ˆè„…è¿«ã¯ã‚„ã‚ã¦ã»ã—ã„ã¨è¨€ã£ã¦ã„ã‚‹ã®ã«ï¼‰']
  print(sengiri.tokenize('æ¥½ã—ã‹ã£ãŸw ã¾ãŸéŠã¼www'))
  #=>['æ¥½ã—ã‹ã£ãŸw', 'ã¾ãŸéŠã¼www']
  print(sengiri.tokenize('http://www.inpaku.go.jp/'))
  #=>['http://www.inpaku.go.jp/']

.. |travis| image:: https://travis-ci.org/ikegami-yukino/sengiri.svg?branch=master
    :target: https://travis-ci.org/ikegami-yukino/sengiri
    :alt: travis-ci.org

.. |coveralls| image:: https://coveralls.io/repos/ikegami-yukino/sengiri/badge.svg?branch=master&service=github
    :target: https://coveralls.io/github/ikegami-yukino/sengiri?branch=master
    :alt: coveralls.io

.. |pyversion| image:: https://img.shields.io/pypi/pyversions/sengiri.svg

.. |version| image:: https://img.shields.io/pypi/v/sengiri.svg
    :target: http://pypi.python.org/pypi/sengiri/
    :alt: latest version

.. |license| image:: https://img.shields.io/pypi/l/sengiri.svg
    :target: http://pypi.python.org/pypi/sengiri/
    :alt: license


CHANGES
=======

0.2.1 (2019-10-12)
------------------

- Works well with also a text including emoticon and www (Laughing expression)
- Always treat emoji to delimiter regardless MeCab's POS

0.1.1 (2019-10-05)
------------------

- First release


